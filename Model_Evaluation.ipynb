{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from model.evaluation import eval_model\n",
    "from model.qwenvl.loader import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "images",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "object",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3828f950-6737-4833-b548-a39a3423b724",
       "rows": [
        [
         "0",
         "Robot_Arm_Data/bright_default_cam/image_20250325_082143_1.png",
         "A drink with some fizz would really hit the spot.",
         "<obj>coke_can</obj> <pose>0.635,-0.1,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>coke_can</obj>"
        ],
        [
         "1",
         "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150318_2.png",
         "Where can I pour my juice?",
         "<obj>plastic_cup</obj> <pose>0.71,-1.185,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "dark_offset6_cafe1_cafetable",
         "<obj>plastic_cup</obj>"
        ],
        [
         "2",
         "Robot_Arm_Data/dark_offset13_field_marbletable/image_20250401_104450_0.png",
         "A few strawberries would make this snack perfect.",
         "<obj>strawberry</obj> <pose>0.655,-0.765,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset13_field_marbletable",
         "<obj>strawberry</obj>"
        ],
        [
         "3",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_111530_2.png",
         "This ramen needs a bowl so I can eat it properly.",
         "<obj>bowl</obj> <pose>0.385,-0.02,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>bowl</obj>"
        ],
        [
         "4",
         "Robot_Arm_Data/bright_offset16_cafe1_marbletable/image_20250401_132933_1.png",
         "A screen with access to everything I need would be perfect.",
         "<obj>samsung_j8_black</obj> <pose>0.635,0.065,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset16_cafe1_marbletable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "5",
         "Robot_Arm_Data/bright_default_cam/image_20250324_151953_2.png",
         "A piece of fruit sounds like a good idea.",
         "<obj>peach</obj> <pose>0.605,-1.24,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>peach</obj>"
        ],
        [
         "6",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_135618_1.png",
         "Please restore your default posture.",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>reset</obj>"
        ],
        [
         "7",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_142140_1.png",
         "Can you reposition yourself to where you began?",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>reset</obj>"
        ],
        [
         "8",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_141654_1.png",
         "Return to the base location.",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>reset</obj>"
        ],
        [
         "9",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112307_0.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.835,-1.19,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>strawberry</obj>"
        ],
        [
         "10",
         "Robot_Arm_Data/bright_offset16_cafe1_marbletable/image_20250401_131530_0.png",
         "A piece of fruit with a firm outside and juicy inside sounds great.",
         "<obj>peach</obj> <pose>0.49,-1.12,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset16_cafe1_marbletable",
         "<obj>peach</obj>"
        ],
        [
         "11",
         "Robot_Arm_Data/dark_offset15_cafe2_marbletable/image_20250401_120151_0.png",
         "I should find a fruit that grows in small clusters and has a fresh aroma.",
         "<obj>strawberry</obj> <pose>0.945,-1.04,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset15_cafe2_marbletable",
         "<obj>strawberry</obj>"
        ],
        [
         "12",
         "Robot_Arm_Data/bright_offset1/image_20250325_225553_0.png",
         "Something in a bottle with bubbles would be nice.",
         "<obj>coke_can</obj> <pose>0.515,-1.09,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset1",
         "<obj>coke_can</obj>"
        ],
        [
         "13",
         "Robot_Arm_Data/bright_offset12_field_marbletable/image_20250401_100222_0.png",
         "Where is the fresh fruit?",
         "<obj>peach</obj> <pose>0.71,-0.55,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset12_field_marbletable",
         "<obj>peach</obj>"
        ],
        [
         "14",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_111955_0.png",
         "This meal would be easier to eat with something to hold it.",
         "<obj>bowl</obj> <pose>0.565,-0.845,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>bowl</obj>"
        ],
        [
         "15",
         "Robot_Arm_Data/bright_default_cam/image_20250324_164837_0.png",
         "I should check the notifications I just heard.",
         "<obj>samsung_j8_black</obj> <pose>0.76,-1.035,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "16",
         "Robot_Arm_Data/bright_offset7_mud_cafetable/image_20250331_152035_2.png",
         "A carbonated drink sounds like a good idea.",
         "<obj>coke_can</obj> <pose>0.805,-1.02,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset7_mud_cafetable",
         "<obj>coke_can</obj>"
        ],
        [
         "17",
         "Robot_Arm_Data/dark_offset9_cafe2_cafetable/image_20250401_083342_2.png",
         "A carbonated drink sounds like a good idea.",
         "<obj>coke_can</obj> <pose>0.78,-0.415,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset9_cafe2_cafetable",
         "<obj>coke_can</obj>"
        ],
        [
         "18",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_141617_1.png",
         "Where can I pour my juice?",
         "<obj>plastic_cup</obj> <pose>0.71,-1.185,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>plastic_cup</obj>"
        ],
        [
         "19",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_141303_0.png",
         "A drink with some fizz would really hit the spot.",
         "<obj>coke_can</obj> <pose>0.675,-0.88,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>coke_can</obj>"
        ],
        [
         "20",
         "Robot_Arm_Data/bright_default_cam/image_20250324_154056_0.png",
         "I should check the notifications I just heard.",
         "<obj>samsung_j8_black</obj> <pose>0.59,-1.12,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "21",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112355_2.png",
         "I need to respond to an email.",
         "<obj>samsung_j8_black</obj> <pose>0.675,-0.805,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "22",
         "Robot_Arm_Data/dark_offset11_field_cafetable/image_20250401_094022_2.png",
         "I want to serve my salad properly instead of just piling it up.",
         "<obj>bowl</obj> <pose>0.57,-0.94,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "dark_offset11_field_cafetable",
         "<obj>bowl</obj>"
        ],
        [
         "23",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_164511_0.png",
         "Is there something disposable I can use for this?",
         "<obj>plastic_cup</obj> <pose>0.635,-1.07,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>plastic_cup</obj>"
        ],
        [
         "24",
         "Robot_Arm_Data/bright_offset12_field_marbletable/image_20250401_100355_1.png",
         "Let me look up the directions for where I'm going.",
         "<obj>samsung_j8_black</obj> <pose>0.545,-0.235,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset12_field_marbletable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "25",
         "Robot_Arm_Data/bright_offset3_mud/image_20250326_104831_1.png",
         "I wonder if anyone has texted me back yet.",
         "<obj>samsung_j8_black</obj> <pose>0.81,-0.87,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset3_mud",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "26",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_140832_0.png",
         "I should add some strawberries to this dessert.",
         "<obj>strawberry</obj> <pose>0.545,-0.145,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>strawberry</obj>"
        ],
        [
         "27",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_163008_2.png",
         "I should grab a bottle of something with a recognizable taste.",
         "<obj>coke_can</obj> <pose>0.67,-0.53,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>coke_can</obj>"
        ],
        [
         "28",
         "Robot_Arm_Data/dark_offset2/image_20250325_162648_2.png",
         "I need a cold refreshment.",
         "<obj>coke_can</obj> <pose>0.685,-0.18,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset2",
         "<obj>coke_can</obj>"
        ],
        [
         "29",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_134605_1.png",
         "Whereâ€™s something I can grab for a light snack?",
         "<obj>peach</obj> <pose>0.505,-0.04,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>peach</obj>"
        ],
        [
         "30",
         "Robot_Arm_Data/dark_offset13_field_marbletable/image_20250401_104212_0.png",
         "I should find something I can reuse to reduce waste.",
         "<obj>plastic_cup</obj> <pose>0.705,-0.41,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "dark_offset13_field_marbletable",
         "<obj>plastic_cup</obj>"
        ],
        [
         "31",
         "Robot_Arm_Data/bright_default_cam/image_20250324_145844_2.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.655,-0.685,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>"
        ],
        [
         "32",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_141150_1.png",
         "This meal would taste better with a peach on the side.",
         "<obj>peach</obj> <pose>0.81,-0.285,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>peach</obj>"
        ],
        [
         "33",
         "Robot_Arm_Data/bright_offset12_field_marbletable/image_20250401_100130_2.png",
         "I want to grab a canned soda.",
         "<obj>coke_can</obj> <pose>0.725,-0.55,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset12_field_marbletable",
         "<obj>coke_can</obj>"
        ],
        [
         "34",
         "Robot_Arm_Data/bright_default_cam/image_20250325_082106_1.png",
         "I need to check my notifications.",
         "<obj>samsung_j8_black</obj> <pose>0.525,-0.09,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "35",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_163200_1.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.75,-1.25,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>strawberry</obj>"
        ],
        [
         "36",
         "Robot_Arm_Data/dark_offset2/image_20250325_162243_1.png",
         "Thereâ€™s something I need to search up quickly.",
         "<obj>samsung_j8_black</obj> <pose>0.59,-1.255,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset2",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "37",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083217_1.png",
         "A handful of something sweet would be refreshing.",
         "<obj>strawberry</obj> <pose>0.83,-1.215,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>"
        ],
        [
         "38",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_134025_2.png",
         "I need to take a picture.",
         "<obj>samsung_j8_black</obj> <pose>0.79,-0.815,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "39",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_135528_0.png",
         "A smartphone would help me look up directions.",
         "<obj>samsung_j8_black</obj> <pose>0.69,-0.3,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "40",
         "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150808_1.png",
         "I'm thirsty for some sweet drinks.",
         "<obj>coke_can</obj> <pose>0.77,-0.57,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset6_cafe1_cafetable",
         "<obj>coke_can</obj>"
        ],
        [
         "41",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_164834_1.png",
         "A fruit with a pit in the middle would be a nice snack.",
         "<obj>peach</obj> <pose>0.46,-1.225,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>peach</obj>"
        ],
        [
         "42",
         "Robot_Arm_Data/dark_offset13_field_marbletable/image_20250401_105322_1.png",
         "I need to serve this dish properly.",
         "<obj>bowl</obj> <pose>0.44,-0.325,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "dark_offset13_field_marbletable",
         "<obj>bowl</obj>"
        ],
        [
         "43",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_142012_1.png",
         "I want to put some soup in something.",
         "<obj>bowl</obj> <pose>0.815,-0.925,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>bowl</obj>"
        ],
        [
         "44",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083217_2.png",
         "I should add some strawberries to this dessert.",
         "<obj>strawberry</obj> <pose>0.83,-1.215,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>"
        ],
        [
         "45",
         "Robot_Arm_Data/dark_offset9_cafe2_cafetable/image_20250401_082929_2.png",
         "I need to check my email before I forget.",
         "<obj>samsung_j8_black</obj> <pose>0.875,-0.8,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset9_cafe2_cafetable",
         "<obj>samsung_j8_black</obj>"
        ],
        [
         "46",
         "Robot_Arm_Data/bright_default_cam/image_20250324_150749_0.png",
         "I want to put some soup in something.",
         "<obj>bowl</obj> <pose>0.48,-0.26,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>bowl</obj>"
        ],
        [
         "47",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083538_0.png",
         "I want something slightly tangy but sweet.",
         "<obj>strawberry</obj> <pose>0.615,-1.085,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>"
        ],
        [
         "48",
         "Robot_Arm_Data/bright_default_cam/image_20250325_084355_1.png",
         "I need to separate this portion from the rest.",
         "<obj>bowl</obj> <pose>0.655,-0.55,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>bowl</obj>"
        ],
        [
         "49",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112031_0.png",
         "I need something that pairs well with cream or chocolate.",
         "<obj>strawberry</obj> <pose>0.86,-1.055,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>strawberry</obj>"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 392
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>name</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>A drink with some fizz would really hit the spot.</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt; &lt;pose&gt;0.635,-0.1,0.72&lt;/pos...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robot_Arm_Data/dark_offset6_cafe1_cafetable/im...</td>\n",
       "      <td>Where can I pour my juice?</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt; &lt;pose&gt;0.71,-1.185,0.548...</td>\n",
       "      <td>dark_offset6_cafe1_cafetable</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robot_Arm_Data/dark_offset13_field_marbletable...</td>\n",
       "      <td>A few strawberries would make this snack perfect.</td>\n",
       "      <td>&lt;obj&gt;strawberry&lt;/obj&gt; &lt;pose&gt;0.655,-0.765,0.58&lt;...</td>\n",
       "      <td>dark_offset13_field_marbletable</td>\n",
       "      <td>&lt;obj&gt;strawberry&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robot_Arm_Data/bright_offset14_cafe2_marbletab...</td>\n",
       "      <td>This ramen needs a bowl so I can eat it properly.</td>\n",
       "      <td>&lt;obj&gt;bowl&lt;/obj&gt; &lt;pose&gt;0.385,-0.02,0.58&lt;/pose&gt; ...</td>\n",
       "      <td>bright_offset14_cafe2_marbletable</td>\n",
       "      <td>&lt;obj&gt;bowl&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robot_Arm_Data/bright_offset16_cafe1_marbletab...</td>\n",
       "      <td>A screen with access to everything I need woul...</td>\n",
       "      <td>&lt;obj&gt;samsung_j8_black&lt;/obj&gt; &lt;pose&gt;0.635,0.065,...</td>\n",
       "      <td>bright_offset16_cafe1_marbletable</td>\n",
       "      <td>&lt;obj&gt;samsung_j8_black&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>I want something sweet and juicy to eat.</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt; &lt;pose&gt;0.95,-0.71,0.63&lt;/pose&gt; ...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>I'm craving a soft fruit.</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt; &lt;pose&gt;0.77,-0.275,0.63&lt;/pose&gt;...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Robot_Arm_Data/dark_offset15_cafe2_marbletable...</td>\n",
       "      <td>Something cold and fizzy would go well with my...</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt; &lt;pose&gt;0.825,-0.3,0.72&lt;/pos...</td>\n",
       "      <td>dark_offset15_cafe2_marbletable</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>I should grab something that can hold both col...</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt; &lt;pose&gt;0.67,-0.705,0.548...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Robot_Arm_Data/dark_offset4_mud/image_20250326...</td>\n",
       "      <td>I should find something I can reuse to reduce ...</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt; &lt;pose&gt;0.615,-1.195,0.54...</td>\n",
       "      <td>dark_offset4_mud</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                images  \\\n",
       "0    Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "1    Robot_Arm_Data/dark_offset6_cafe1_cafetable/im...   \n",
       "2    Robot_Arm_Data/dark_offset13_field_marbletable...   \n",
       "3    Robot_Arm_Data/bright_offset14_cafe2_marbletab...   \n",
       "4    Robot_Arm_Data/bright_offset16_cafe1_marbletab...   \n",
       "..                                                 ...   \n",
       "387  Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "388  Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "389  Robot_Arm_Data/dark_offset15_cafe2_marbletable...   \n",
       "390  Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "391  Robot_Arm_Data/dark_offset4_mud/image_20250326...   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    A drink with some fizz would really hit the spot.   \n",
       "1                           Where can I pour my juice?   \n",
       "2    A few strawberries would make this snack perfect.   \n",
       "3    This ramen needs a bowl so I can eat it properly.   \n",
       "4    A screen with access to everything I need woul...   \n",
       "..                                                 ...   \n",
       "387           I want something sweet and juicy to eat.   \n",
       "388                          I'm craving a soft fruit.   \n",
       "389  Something cold and fizzy would go well with my...   \n",
       "390  I should grab something that can hold both col...   \n",
       "391  I should find something I can reuse to reduce ...   \n",
       "\n",
       "                                                output  \\\n",
       "0    <obj>coke_can</obj> <pose>0.635,-0.1,0.72</pos...   \n",
       "1    <obj>plastic_cup</obj> <pose>0.71,-1.185,0.548...   \n",
       "2    <obj>strawberry</obj> <pose>0.655,-0.765,0.58<...   \n",
       "3    <obj>bowl</obj> <pose>0.385,-0.02,0.58</pose> ...   \n",
       "4    <obj>samsung_j8_black</obj> <pose>0.635,0.065,...   \n",
       "..                                                 ...   \n",
       "387  <obj>peach</obj> <pose>0.95,-0.71,0.63</pose> ...   \n",
       "388  <obj>peach</obj> <pose>0.77,-0.275,0.63</pose>...   \n",
       "389  <obj>coke_can</obj> <pose>0.825,-0.3,0.72</pos...   \n",
       "390  <obj>plastic_cup</obj> <pose>0.67,-0.705,0.548...   \n",
       "391  <obj>plastic_cup</obj> <pose>0.615,-1.195,0.54...   \n",
       "\n",
       "                                  name                       object  \n",
       "0                   bright_default_cam          <obj>coke_can</obj>  \n",
       "1         dark_offset6_cafe1_cafetable       <obj>plastic_cup</obj>  \n",
       "2      dark_offset13_field_marbletable        <obj>strawberry</obj>  \n",
       "3    bright_offset14_cafe2_marbletable              <obj>bowl</obj>  \n",
       "4    bright_offset16_cafe1_marbletable  <obj>samsung_j8_black</obj>  \n",
       "..                                 ...                          ...  \n",
       "387                 bright_default_cam             <obj>peach</obj>  \n",
       "388                 bright_default_cam             <obj>peach</obj>  \n",
       "389    dark_offset15_cafe2_marbletable          <obj>coke_can</obj>  \n",
       "390                 bright_default_cam       <obj>plastic_cup</obj>  \n",
       "391                   dark_offset4_mud       <obj>plastic_cup</obj>  \n",
       "\n",
       "[392 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('Robot_Arm_Data/test.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060. Num GPUs = 1. Max memory: 12.0 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model, processor = load_model(r'checkpoints\\Llava-Output\\V1-p2\\checkpoint-147') # Llava            \n",
    "# model, processor = load_model(r'checkpoints\\LlamaVision-Output\\checkpoint-441') # LlamaVision\n",
    "# model, processor = load_model(r'checkpoints\\Qwen-Output\\2B\\V4\\checkpoint-1320') # Qwen2B\n",
    "# model, processor = load_model(r'checkpoints\\Qwen-Output\\7B\\V2\\P4\\checkpoint-300') # Qwen7B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_message = 'You are a Visual Language Model Trained to output robot arm end-effectors parameters.' \\\n",
    "# 'Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.' \\\n",
    "# 'The camera position relative to the robot arm is also provide inside <camera> </camera> tag, study them to understand object positions from different view angle.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = 'You are a Visual Language Model Trained to output robot arm end-effectors parameters.' \\\n",
    "'Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2B Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 192 records with batch size of 3 per iteration:\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.1001                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.7531      | 0.8699      | 0.8290      |\n",
      "Mean Absolute Error | 0.0586      | 0.0489      | 0.0153      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 17.5682                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 11.8585     | 3.7846      | 10.3396     |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.79      0.88        24\n",
      "        coke_can       0.97      1.00      0.98        32\n",
      "           peach       0.94      0.97      0.96        33\n",
      "     plastic_cup       0.90      1.00      0.95        28\n",
      "           reset       1.00      1.00      1.00        16\n",
      "samsung_j8_black       1.00      1.00      1.00        30\n",
      "      strawberry       1.00      1.00      1.00        29\n",
      "\n",
      "        accuracy                           0.97       192\n",
      "       macro avg       0.97      0.97      0.97       192\n",
      "    weighted avg       0.97      0.97      0.97       192\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=3, return_raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 3 per iteration:\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 2 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.1089                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.7573      | 0.8130      | 0.5394      |\n",
      "Mean Absolute Error | 0.0505      | 0.0575      | 0.0363      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 11.9194                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 6.8334      | 5.4204      | 6.7619      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.80      0.89        60\n",
      "        coke_can       0.97      0.98      0.98        66\n",
      "           peach       0.85      0.97      0.91        60\n",
      "     plastic_cup       0.89      0.97      0.93        58\n",
      "           reset       0.83      1.00      0.91        29\n",
      "samsung_j8_black       1.00      0.98      0.99        57\n",
      "      strawberry       0.96      0.85      0.90        60\n",
      "\n",
      "        accuracy                           0.93       390\n",
      "       macro avg       0.93      0.94      0.93       390\n",
      "    weighted avg       0.94      0.93      0.93       390\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('V3_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 4 per iteration:\n",
      "All Images will be resized to (854, 480)\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 3 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "CasualLM Evaluation:\n",
      "---------------------------------------------------------------\n",
      "BLEU Score          |                  0.8428                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Rouge Score         |                  0.8962                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.3856                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.1404      | -0.4170     | 1.0000      |\n",
      "Mean Absolute Error | 0.1239      | 0.3402      | 0.0000      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 3.6854                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 3.0052      | 1.1891      | 2.1114      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      1.00      1.00        57\n",
      "        coke_can       1.00      1.00      1.00        65\n",
      "           peach       1.00      1.00      1.00        61\n",
      "     plastic_cup       1.00      1.00      1.00        57\n",
      "           reset       1.00      1.00      1.00        30\n",
      "samsung_j8_black       1.00      1.00      1.00        58\n",
      "      strawberry       1.00      1.00      1.00        61\n",
      "\n",
      "        accuracy                           1.00       389\n",
      "       macro avg       1.00      1.00      1.00       389\n",
      "    weighted avg       1.00      1.00      1.00       389\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5-balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 6 per iteration:\n",
      "All Images will be resized to (630, 360)\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 2 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.4206                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.4706      | 0.6397      | -4.4945     |\n",
      "Mean Absolute Error | 0.1018      | 0.1400      | 0.2959      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 43.8431                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 35.7609     | 11.6472     | 29.2342     |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.85      0.92        60\n",
      "        coke_can       0.93      1.00      0.96        65\n",
      "           peach       0.94      0.98      0.96        61\n",
      "     plastic_cup       0.93      1.00      0.97        57\n",
      "           reset       0.96      0.93      0.95        28\n",
      "samsung_j8_black       1.00      0.98      0.99        58\n",
      "      strawberry       0.98      0.97      0.98        61\n",
      "\n",
      "        accuracy                           0.96       390\n",
      "       macro avg       0.96      0.96      0.96       390\n",
      "    weighted avg       0.96      0.96      0.96       390\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, size=(630, 360), system_message=system_message, eval_dataset=data, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7B Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 2 per iteration:\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 0 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.0602                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.9281      | 0.9155      | 0.9269      |\n",
      "Mean Absolute Error | 0.0330      | 0.0359      | 0.0048      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 0.0008                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 0.0000      | 0.0000      | 0.0008      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      1.00      1.00        60\n",
      "        coke_can       1.00      1.00      1.00        65\n",
      "           peach       1.00      0.98      0.99        61\n",
      "     plastic_cup       1.00      1.00      1.00        57\n",
      "           reset       1.00      1.00      1.00        30\n",
      "samsung_j8_black       1.00      1.00      1.00        58\n",
      "      strawberry       1.00      1.00      1.00        61\n",
      "          yogurt       0.00      0.00      0.00         0\n",
      "\n",
      "        accuracy                           1.00       392\n",
      "       macro avg       0.88      0.87      0.87       392\n",
      "    weighted avg       1.00      1.00      1.00       392\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 2 per iteration:\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 0 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.0509                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.9298      | 0.9549      | 0.9988      |\n",
      "Mean Absolute Error | 0.0305      | 0.0320      | 0.0008      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 0.4588                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 0.4148      | 0.1066      | 0.1734      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.97      0.98        60\n",
      "        coke_can       0.98      1.00      0.99        65\n",
      "           peach       0.97      0.98      0.98        61\n",
      "     plastic_cup       0.98      1.00      0.99        57\n",
      "           reset       1.00      1.00      1.00        30\n",
      "samsung_j8_black       1.00      1.00      1.00        58\n",
      "      strawberry       0.98      0.97      0.98        61\n",
      "\n",
      "        accuracy                           0.99       392\n",
      "       macro avg       0.99      0.99      0.99       392\n",
      "    weighted avg       0.99      0.99      0.99       392\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 3 per iteration:\n",
      "All Images will be resized to (854, 480)\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 3 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "CasualLM Evaluation:\n",
      "---------------------------------------------------------------\n",
      "BLEU Score          |                  0.8655                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Rouge Score         |                  0.9221                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.0559                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.9059      | 0.9385      | 0.9988      |\n",
      "Mean Absolute Error | 0.0343      | 0.0353      | 0.0008      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 0.4629                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 0.4214      | 0.1057      | 0.1796      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.97      0.98        60\n",
      "        coke_can       0.98      1.00      0.99        65\n",
      "           peach       0.97      0.98      0.98        61\n",
      "     plastic_cup       0.98      1.00      0.99        57\n",
      "           reset       1.00      1.00      1.00        30\n",
      "samsung_j8_black       1.00      1.00      1.00        58\n",
      "      strawberry       0.98      0.97      0.97        58\n",
      "\n",
      "        accuracy                           0.99       389\n",
      "       macro avg       0.99      0.99      0.99       389\n",
      "    weighted avg       0.99      0.99      0.99       389\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# V2 P4\n",
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 2 per iteration:\n",
      "All Images will be resized to (854, 480)\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 208 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "CasualLM Evaluation:\n",
      "---------------------------------------------------------------\n",
      "BLEU Score          |                  0.7662                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Rouge Score         |                  0.8834                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.0700                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.9016      | 0.9252      | 0.4845      |\n",
      "Mean Absolute Error | 0.0363      | 0.0432      | 0.0046      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 0.1002                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 0.0467      | 0.0859      | 0.0246      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                         bowl       1.00      1.00      1.00        31\n",
      "                     coke_can       1.00      1.00      1.00        15\n",
      "                        peach       1.00      1.00      1.00        21\n",
      "                  plastic_cup       1.00      0.98      0.99        55\n",
      "           plastic_cup_1200ml       0.00      0.00      0.00         0\n",
      "                        reset       1.00      1.00      1.00         1\n",
      "             samsung_j8_black       1.00      0.57      0.72        51\n",
      "samsung_j8_black_2016_edition       0.00      0.00      0.00         0\n",
      "     samsung_j8_black_edition       0.00      0.00      0.00         0\n",
      "  samsung_j8_black_framed.png       0.00      0.00      0.00         0\n",
      "    samsung_j8_black_unlocked       0.00      0.00      0.00         0\n",
      "                   strawberry       1.00      1.00      1.00        10\n",
      "\n",
      "                     accuracy                           0.88       184\n",
      "                    macro avg       0.58      0.55      0.56       184\n",
      "                 weighted avg       1.00      0.88      0.92       184\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=2, temperature=0.5, min_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "images",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "object",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pos_out",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ori_out",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "obj_out",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "raw_out",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pos_truth",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ori_truth",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "obj_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "format_check",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "40631c28-fd0b-4189-a2b8-d8fa1ca44480",
       "rows": [
        [
         "1",
         "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150318_2.png",
         "Where can I pour my juice?",
         "<obj>plastic_cup</obj> <pose>0.71,-1.185,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "dark_offset6_cafe1_cafetable",
         "<obj>plastic_cup</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nWhere can I pour my juice? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.71', '-1.185', '0.548']",
         "['0.35478', '0.71881', '0.30505', '0.5141']",
         "plastic_cup",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "2",
         "Robot_Arm_Data/dark_offset13_field_marbletable/image_20250401_104450_0.png",
         "A few strawberries would make this snack perfect.",
         "<obj>strawberry</obj> <pose>0.655,-0.765,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset13_field_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA few strawberries would make this snack perfect. [/INST] <obj>strawberry</obj>strawberry.3d <pose>0.61,-0.685,0.58 <orient>0.37508,0.92699,-0.00045,0.00284.",
         "['0.655', '-0.765', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "3",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_111530_2.png",
         "This ramen needs a bowl so I can eat it properly.",
         "<obj>bowl</obj> <pose>0.385,-0.02,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>bowl</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nThis ramen needs a bowl so I can eat it properly. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.385', '-0.02', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "5",
         "Robot_Arm_Data/bright_default_cam/image_20250324_151953_2.png",
         "A piece of fruit sounds like a good idea.",
         "<obj>peach</obj> <pose>0.605,-1.24,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA piece of fruit sounds like a good idea. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.605', '-1.24', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "6",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_135618_1.png",
         "Please restore your default posture.",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>reset</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nPlease restore your default posture. [/INST] <obj>reset\\s return\\s [INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.32', '-0.65897', '1.5002']",
         "['0.70711', '0.0006', '0.00068', '0.70711']",
         "reset",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "7",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_142140_1.png",
         "Can you reposition yourself to where you began?",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>reset</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nCan you reposition yourself to where you began? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.32', '-0.65897', '1.5002']",
         "['0.70711', '0.0006', '0.00068', '0.70711']",
         "reset",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "8",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_141654_1.png",
         "Return to the base location.",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>reset</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nReturn to the base location. [/INST] <obj>reset</obj>reset<\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.32', '-0.65897', '1.5002']",
         "['0.70711', '0.0006', '0.00068', '0.70711']",
         "reset",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "9",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112307_0.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.835,-1.19,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIâ€™m looking for something juicy and bite-sized. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.835', '-1.19', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "10",
         "Robot_Arm_Data/bright_offset16_cafe1_marbletable/image_20250401_131530_0.png",
         "A piece of fruit with a firm outside and juicy inside sounds great.",
         "<obj>peach</obj> <pose>0.49,-1.12,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset16_cafe1_marbletable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA piece of fruit with a firm outside and juicy inside sounds great. [/INST] <obj>peach</obj>peach:peach <pose>0.545,-1.095,0.63 <orient>0.4468,0.8508,0.2185,0.147 <w>0.5897,0.7138,0.2005,0.3050 <\\s>",
         "['0.49', '-1.12', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "11",
         "Robot_Arm_Data/dark_offset15_cafe2_marbletable/image_20250401_120151_0.png",
         "I should find a fruit that grows in small clusters and has a fresh aroma.",
         "<obj>strawberry</obj> <pose>0.945,-1.04,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset15_cafe2_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI should find a fruit that grows in small clusters and has a fresh aroma. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.945', '-1.04', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "13",
         "Robot_Arm_Data/bright_offset12_field_marbletable/image_20250401_100222_0.png",
         "Where is the fresh fruit?",
         "<obj>peach</obj> <pose>0.71,-0.55,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset12_field_marbletable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nWhere is the fresh fruit? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.71', '-0.55', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "14",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_111955_0.png",
         "This meal would be easier to eat with something to hold it.",
         "<obj>bowl</obj> <pose>0.565,-0.845,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>bowl</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nThis meal would be easier to eat with something to hold it. [/INST] <obj>bowl</obj>bowl</s> <p>0.52,-0.805,0.58</p> <r>0.545,-0.637,0.58</r> <q>0.4468,0.8508,0.2185,0.147</q>",
         "['0.565', '-0.845', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "15",
         "Robot_Arm_Data/bright_default_cam/image_20250324_164837_0.png",
         "I should check the notifications I just heard.",
         "<obj>samsung_j8_black</obj> <pose>0.76,-1.035,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI should check the notifications I just heard. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.76', '-1.035', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "16",
         "Robot_Arm_Data/bright_offset7_mud_cafetable/image_20250331_152035_2.png",
         "A carbonated drink sounds like a good idea.",
         "<obj>coke_can</obj> <pose>0.805,-1.02,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset7_mud_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA carbonated drink sounds like a good idea. [/INST] I'm not sure what you're asking for, but I'll do my best to help. [/INST] I need something fizzy. [/INST] I'm craving something with a little kick to it. [/INST\nI need something that pairs well with others. [/\nI need something that can hold its own. [/\nI need something that can stand on its own two feet. [/\nI need something that can reach for",
         "['0.805', '-1.02', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "17",
         "Robot_Arm_Data/dark_offset9_cafe2_cafetable/image_20250401_083342_2.png",
         "A carbonated drink sounds like a good idea.",
         "<obj>coke_can</obj> <pose>0.78,-0.415,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset9_cafe2_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA carbonated drink sounds like a good idea. [/INST] I'm not sure what you're asking for, but I'll do my best to help. [/INST] I need something fizzy. [/INST\nA can of Coke would be perfect. [/\nI need a cold beverage. [/\nI need something with a kick. [/\nI need a caffeine fix. [/\nI need a pick-me-up. [/\nI need a boost. [/",
         "['0.78', '-0.415', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "19",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_141303_0.png",
         "A drink with some fizz would really hit the spot.",
         "<obj>coke_can</obj> <pose>0.675,-0.88,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA drink with some fizz would really hit the spot. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.675', '-0.88', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "21",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112355_2.png",
         "I need to respond to an email.",
         "<obj>samsung_j8_black</obj> <pose>0.675,-0.805,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need to respond to an email. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.675', '-0.805', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "22",
         "Robot_Arm_Data/dark_offset11_field_cafetable/image_20250401_094022_2.png",
         "I want to serve my salad properly instead of just piling it up.",
         "<obj>bowl</obj> <pose>0.57,-0.94,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "dark_offset11_field_cafetable",
         "<obj>bowl</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want to serve my salad properly instead of just piling it up. [/INST] <obj>bowl</obj>bowl <pose>0.562,-0.922,0.58 <orient>0.4468,0.8508,0.2185,0.147 <orient>0.37508,0.92699,-0.00045,0.00284 <\\s>",
         "['0.57', '-0.94', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "23",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_164511_0.png",
         "Is there something disposable I can use for this?",
         "<obj>plastic_cup</obj> <pose>0.635,-1.07,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>plastic_cup</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIs there something disposable I can use for this? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.635', '-1.07', '0.548']",
         "['0.35478', '0.71881', '0.30505', '0.5141']",
         "plastic_cup",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "25",
         "Robot_Arm_Data/bright_offset3_mud/image_20250326_104831_1.png",
         "I wonder if anyone has texted me back yet.",
         "<obj>samsung_j8_black</obj> <pose>0.81,-0.87,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset3_mud",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI wonder if anyone has texted me back yet. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.81', '-0.87', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "26",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_140832_0.png",
         "I should add some strawberries to this dessert.",
         "<obj>strawberry</obj> <pose>0.545,-0.145,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI should add some strawberries to this dessert. [/INST] <obj>strawberry</obj>strawberry.3d.obj<\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s",
         "['0.545', '-0.145', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "27",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_163008_2.png",
         "I should grab a bottle of something with a recognizable taste.",
         "<obj>coke_can</obj> <pose>0.67,-0.53,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI should grab a bottle of something with a recognizable taste. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.67', '-0.53', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "29",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_134605_1.png",
         "Whereâ€™s something I can grab for a light snack?",
         "<obj>peach</obj> <pose>0.505,-0.04,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nWhereâ€™s something I can grab for a light snack? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.505', '-0.04', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "31",
         "Robot_Arm_Data/bright_default_cam/image_20250324_145844_2.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.655,-0.685,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIâ€™m looking for something juicy and bite-sized. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.655', '-0.685', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "32",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_141150_1.png",
         "This meal would taste better with a peach on the side.",
         "<obj>peach</obj> <pose>0.81,-0.285,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nThis meal would taste better with a peach on the side. [/INST] <obj>peach</obj>peach.peach <pose>0.785,-0.26,0.63 <orient>0.4468,0.8508,0.2185,0.147 <orient>0.37508,0.92699,-0.00045,0.00284 <\\s>",
         "['0.81', '-0.285', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "33",
         "Robot_Arm_Data/bright_offset12_field_marbletable/image_20250401_100130_2.png",
         "I want to grab a canned soda.",
         "<obj>coke_can</obj> <pose>0.725,-0.55,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset12_field_marbletable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want to grab a canned soda. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.725', '-0.55', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "35",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_163200_1.png",
         "Iâ€™m looking for something juicy and bite-sized.",
         "<obj>strawberry</obj> <pose>0.75,-1.25,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIâ€™m looking for something juicy and bite-sized. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.75', '-1.25', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "37",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083217_1.png",
         "A handful of something sweet would be refreshing.",
         "<obj>strawberry</obj> <pose>0.83,-1.215,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA handful of something sweet would be refreshing. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.83', '-1.215', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "39",
         "Robot_Arm_Data/dark_offset17_cafe1_marbletable/image_20250401_135528_0.png",
         "A smartphone would help me look up directions.",
         "<obj>samsung_j8_black</obj> <pose>0.69,-0.3,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset17_cafe1_marbletable",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA smartphone would help me look up directions. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.69', '-0.3', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "40",
         "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150808_1.png",
         "I'm thirsty for some sweet drinks.",
         "<obj>coke_can</obj> <pose>0.77,-0.57,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset6_cafe1_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI'm thirsty for some sweet drinks. [/INST] <obj>coke_can</obj> <pose>0.705,-0.56,0.725 <orient>0.37508,0.92699,-0.00045,0.00284. <name>coke_can</name>",
         "['0.77', '-0.57', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "41",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_164834_1.png",
         "A fruit with a pit in the middle would be a nice snack.",
         "<obj>peach</obj> <pose>0.46,-1.225,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA fruit with a pit in the middle would be a nice snack. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.46', '-1.225', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "43",
         "Robot_Arm_Data/bright_offset5_cafe1_cafetable/image_20250331_142012_1.png",
         "I want to put some soup in something.",
         "<obj>bowl</obj> <pose>0.815,-0.925,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset5_cafe1_cafetable",
         "<obj>bowl</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want to put some soup in something. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.815', '-0.925', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "44",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083217_2.png",
         "I should add some strawberries to this dessert.",
         "<obj>strawberry</obj> <pose>0.83,-1.215,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI should add some strawberries to this dessert. [/INST] <obj>strawberry</obj>strawberry_strawberry_with_stem<\\s>This is a strawberry with a stem. <\\s>A bright red strawberry with a green stem. <\\s>A small, sweet and juicy fruit. <\\s>A fruit that pairs well with chocolate. <\\s>A fruit thatâ€™s always a crowd-pleaser. <\\s>A fruit thatâ€™s high in",
         "['0.83', '-1.215', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "45",
         "Robot_Arm_Data/dark_offset9_cafe2_cafetable/image_20250401_082929_2.png",
         "I need to check my email before I forget.",
         "<obj>samsung_j8_black</obj> <pose>0.875,-0.8,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset9_cafe2_cafetable",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need to check my email before I forget. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.875', '-0.8', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "46",
         "Robot_Arm_Data/bright_default_cam/image_20250324_150749_0.png",
         "I want to put some soup in something.",
         "<obj>bowl</obj> <pose>0.48,-0.26,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>bowl</obj>",
         "['0.62', '-0.625', '0.58']",
         "['0.58', '-0.58', '0.307']",
         "bowl",
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want to put some soup in something. [/INST] <obj>bowl</obj> <pose>0.62,-0.625,0.58</pose> <orient>0.58,-0.58,0.307</orient> <in>0.58,-0.58,0.307</in> <out>bowl</out> <in>soup</in> <out>bowl</out> <in>soup",
         "['0.48', '-0.26', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['incorrect orientation format']"
        ],
        [
         "47",
         "Robot_Arm_Data/bright_default_cam/image_20250325_083538_0.png",
         "I want something slightly tangy but sweet.",
         "<obj>strawberry</obj> <pose>0.615,-1.085,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want something slightly tangy but sweet. [/INST] <\\s>",
         "['0.615', '-1.085', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "49",
         "Robot_Arm_Data/bright_offset14_cafe2_marbletable/image_20250401_112031_0.png",
         "I need something that pairs well with cream or chocolate.",
         "<obj>strawberry</obj> <pose>0.86,-1.055,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset14_cafe2_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need something that pairs well with cream or chocolate. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.86', '-1.055', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "50",
         "Robot_Arm_Data/bright_offset16_cafe1_marbletable/image_20250401_133125_2.png",
         "A fruit that doesnâ€™t need peeling but tastes delicious would be ideal.",
         "<obj>strawberry</obj> <pose>0.985,-0.685,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset16_cafe1_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA fruit that doesnâ€™t need peeling but tastes delicious would be ideal. [/INST] <obj>strawberry</obj>strawberry.obj <pose>0.905,-0.645,0.58. <orient>0.37508,0.92699,-0.00045,0.00284.orient_orient_w,0.0006,0.00284,0.37508.orient_",
         "['0.985', '-0.685', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "51",
         "Robot_Arm_Data/dark_offset15_cafe2_marbletable/image_20250401_121004_0.png",
         "I need something disposable to drink out of.",
         "<obj>plastic_cup</obj> <pose>0.67,-1.02,0.548</pose> <orient>0.35478,0.71881,0.30505,0.5141</orient>",
         "dark_offset15_cafe2_marbletable",
         "<obj>plastic_cup</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need something disposable to drink out of. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.67', '-1.02', '0.548']",
         "['0.35478', '0.71881', '0.30505', '0.5141']",
         "plastic_cup",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "53",
         "Robot_Arm_Data/bright_default_cam/image_20250324_165943_1.png",
         "Is there something sugary to drink around here?",
         "<obj>coke_can</obj> <pose>0.705,-0.175,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIs there something sugary to drink around here? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.705', '-0.175', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "55",
         "Robot_Arm_Data/dark_offset9_cafe2_cafetable/image_20250401_083655_1.png",
         "Iâ€™m looking for a fruit thatâ€™s small, sweet, and easy to eat.",
         "<obj>strawberry</obj> <pose>0.675,-0.12,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset9_cafe2_cafetable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nIâ€™m looking for a fruit thatâ€™s small, sweet, and easy to eat. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.675', '-0.12', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "57",
         "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150039_0.png",
         "I want something fizzy to drink.",
         "<obj>coke_can</obj> <pose>0.555,-1.28,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "dark_offset6_cafe1_cafetable",
         "<obj>coke_can</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI want something fizzy to drink. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.555', '-1.28', '0.72']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "coke_can",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "59",
         "Robot_Arm_Data/bright_offset18_mud_marbletable/image_20250401_141059_0.png",
         "A juicy fruit with a soft bite is exactly what I want.",
         "<obj>strawberry</obj> <pose>0.86,-0.3,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset18_mud_marbletable",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA juicy fruit with a soft bite is exactly what I want. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.86', '-0.3', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "61",
         "Robot_Arm_Data/bright_default_cam/image_20250324_165337_1.png",
         "A few strawberries would make this snack perfect.",
         "<obj>strawberry</obj> <pose>0.76,-0.475,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_default_cam",
         "<obj>strawberry</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA few strawberries would make this snack perfect. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.76', '-0.475', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "strawberry",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "62",
         "Robot_Arm_Data/bright_default_cam/image_20250324_164429_1.png",
         "Move back to the neutral state.",
         "<obj>reset</obj> <pose>0.32,-0.65897,1.5002</pose> <orient>0.70711,0.0006,0.00068,0.70711</orient>",
         "bright_default_cam",
         "<obj>reset</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nMove back to the neutral state. [/INST] <obj>reset\\s return\\s ;\\s [INST] <obj>reset\\s return\\s ;\\s [/INST] <obj>reset\\s return\\s ;\\s [INST] <obj>reset\\s return\\s ;\\s [/INST] <obj>reset\\s return\\s ;\\s [/INST\n\nThis meal needs a nice chilled drink to go with it. [/INST] <obj>co",
         "['0.32', '-0.65897', '1.5002']",
         "['0.70711', '0.0006', '0.00068', '0.70711']",
         "reset",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "63",
         "Robot_Arm_Data/bright_offset8_cafe2_cafetable/image_20250331_163429_1.png",
         "I need to look something up on the internet.",
         "<obj>samsung_j8_black</obj> <pose>0.57,-1.105,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset8_cafe2_cafetable",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need to look something up on the internet. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.57', '-1.105', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "64",
         "Robot_Arm_Data/bright_default_cam/image_20250324_170135_0.png",
         "Whereâ€™s the Coke? I could use something fizzy.",
         "<obj>bowl</obj> <pose>0.66,-0.425,0.58</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>bowl</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nWhereâ€™s the Coke? I could use something fizzy. [/INST] <obj>bowl</obj>bowl.obj:bowl.g <pose>0.695,-0.415,0.58 <orient>0.4468,0.8508,0.2185,0.147 <orient>0.37508,0.92699,-0.00045,0.00284 <",
         "['0.66', '-0.425', '0.58']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "bowl",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "65",
         "Robot_Arm_Data/bright_offset10_field_cafetable/image_20250401_085929_1.png",
         "I need my smartphone to check something online.",
         "<obj>samsung_j8_black</obj> <pose>1.025,-0.675,0.58</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>",
         "bright_offset10_field_cafetable",
         "<obj>samsung_j8_black</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nI need my smartphone to check something online. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['1.025', '-0.675', '0.58']",
         "['0.37508', '0.92699', '-0.00045', '0.00284']",
         "samsung_j8_black",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "66",
         "Robot_Arm_Data/bright_default_cam/image_20250324_155912_1.png",
         "A peach would be a great snack right now.",
         "<obj>peach</obj> <pose>0.725,-1.17,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_default_cam",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA peach would be a great snack right now. [/INST] <obj>peach</obj>peach <pose>0.795,-1.11,0.63 <orient>0.4468,0.8508,0.2185,0.147 <w>0.8,0.447,0.2,0.8508 <out>0.37508,0.93918,0",
         "['0.725', '-1.17', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ],
        [
         "67",
         "Robot_Arm_Data/bright_offset10_field_cafetable/image_20250401_085438_1.png",
         "A piece of fruit sounds like a good idea.",
         "<obj>peach</obj> <pose>0.46,-1.225,0.63</pose> <orient>0.4468,0.8508,0.2185,0.147</orient>",
         "bright_offset10_field_cafetable",
         "<obj>peach</obj>",
         null,
         null,
         null,
         "<<SYS>>\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n<</SYS>>\n\n[INST]  \nA piece of fruit sounds like a good idea. [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>",
         "['0.46', '-1.225', '0.63']",
         "['0.4468', '0.8508', '0.2185', '0.147']",
         "peach",
         "['obj count = 0', 'pose count = 0', 'orient count = 0', 'position is not listformat', 'orientation is not list format']"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 313
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>name</th>\n",
       "      <th>object</th>\n",
       "      <th>pos_out</th>\n",
       "      <th>ori_out</th>\n",
       "      <th>obj_out</th>\n",
       "      <th>raw_out</th>\n",
       "      <th>pos_truth</th>\n",
       "      <th>ori_truth</th>\n",
       "      <th>obj_truth</th>\n",
       "      <th>format_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robot_Arm_Data/dark_offset6_cafe1_cafetable/im...</td>\n",
       "      <td>Where can I pour my juice?</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt; &lt;pose&gt;0.71,-1.185,0.548...</td>\n",
       "      <td>dark_offset6_cafe1_cafetable</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.71, -1.185, 0.548]</td>\n",
       "      <td>[0.35478, 0.71881, 0.30505, 0.5141]</td>\n",
       "      <td>plastic_cup</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robot_Arm_Data/dark_offset13_field_marbletable...</td>\n",
       "      <td>A few strawberries would make this snack perfect.</td>\n",
       "      <td>&lt;obj&gt;strawberry&lt;/obj&gt; &lt;pose&gt;0.655,-0.765,0.58&lt;...</td>\n",
       "      <td>dark_offset13_field_marbletable</td>\n",
       "      <td>&lt;obj&gt;strawberry&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.655, -0.765, 0.58]</td>\n",
       "      <td>[0.37508, 0.92699, -0.00045, 0.00284]</td>\n",
       "      <td>strawberry</td>\n",
       "      <td>[pose count = 0, orient count = 0, position is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robot_Arm_Data/bright_offset14_cafe2_marbletab...</td>\n",
       "      <td>This ramen needs a bowl so I can eat it properly.</td>\n",
       "      <td>&lt;obj&gt;bowl&lt;/obj&gt; &lt;pose&gt;0.385,-0.02,0.58&lt;/pose&gt; ...</td>\n",
       "      <td>bright_offset14_cafe2_marbletable</td>\n",
       "      <td>&lt;obj&gt;bowl&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.385, -0.02, 0.58]</td>\n",
       "      <td>[0.4468, 0.8508, 0.2185, 0.147]</td>\n",
       "      <td>bowl</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>A piece of fruit sounds like a good idea.</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt; &lt;pose&gt;0.605,-1.24,0.63&lt;/pose&gt;...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.605, -1.24, 0.63]</td>\n",
       "      <td>[0.4468, 0.8508, 0.2185, 0.147]</td>\n",
       "      <td>peach</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Robot_Arm_Data/dark_offset17_cafe1_marbletable...</td>\n",
       "      <td>Please restore your default posture.</td>\n",
       "      <td>&lt;obj&gt;reset&lt;/obj&gt; &lt;pose&gt;0.32,-0.65897,1.5002&lt;/p...</td>\n",
       "      <td>dark_offset17_cafe1_marbletable</td>\n",
       "      <td>&lt;obj&gt;reset&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.32, -0.65897, 1.5002]</td>\n",
       "      <td>[0.70711, 0.0006, 0.00068, 0.70711]</td>\n",
       "      <td>reset</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>I could use something cold and sweet to drink.</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt; &lt;pose&gt;0.575,-0.375,0.72&lt;/p...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.575, -0.375, 0.72]</td>\n",
       "      <td>[0.37508, 0.92699, -0.00045, 0.00284]</td>\n",
       "      <td>coke_can</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Robot_Arm_Data/dark_default_cam/image_20250325...</td>\n",
       "      <td>I could go for something naturally sweet.</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt; &lt;pose&gt;0.605,-1.22,0.63&lt;/pose&gt;...</td>\n",
       "      <td>dark_default_cam</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.605, -1.22, 0.63]</td>\n",
       "      <td>[0.4468, 0.8508, 0.2185, 0.147]</td>\n",
       "      <td>peach</td>\n",
       "      <td>[orient count = 0, position is not listformat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Robot_Arm_Data/bright_default_cam/image_202503...</td>\n",
       "      <td>I want something sweet and juicy to eat.</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt; &lt;pose&gt;0.95,-0.71,0.63&lt;/pose&gt; ...</td>\n",
       "      <td>bright_default_cam</td>\n",
       "      <td>&lt;obj&gt;peach&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.95, -0.71, 0.63]</td>\n",
       "      <td>[0.4468, 0.8508, 0.2185, 0.147]</td>\n",
       "      <td>peach</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Robot_Arm_Data/dark_offset15_cafe2_marbletable...</td>\n",
       "      <td>Something cold and fizzy would go well with my...</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt; &lt;pose&gt;0.825,-0.3,0.72&lt;/pos...</td>\n",
       "      <td>dark_offset15_cafe2_marbletable</td>\n",
       "      <td>&lt;obj&gt;coke_can&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.825, -0.3, 0.72]</td>\n",
       "      <td>[0.37508, 0.92699, -0.00045, 0.00284]</td>\n",
       "      <td>coke_can</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Robot_Arm_Data/dark_offset4_mud/image_20250326...</td>\n",
       "      <td>I should find something I can reuse to reduce ...</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt; &lt;pose&gt;0.615,-1.195,0.54...</td>\n",
       "      <td>dark_offset4_mud</td>\n",
       "      <td>&lt;obj&gt;plastic_cup&lt;/obj&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;&lt;SYS&gt;&gt;\\nYou are a Visual Language Model Train...</td>\n",
       "      <td>[0.615, -1.195, 0.548]</td>\n",
       "      <td>[0.35478, 0.71881, 0.30505, 0.5141]</td>\n",
       "      <td>plastic_cup</td>\n",
       "      <td>[obj count = 0, pose count = 0, orient count =...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                images  \\\n",
       "1    Robot_Arm_Data/dark_offset6_cafe1_cafetable/im...   \n",
       "2    Robot_Arm_Data/dark_offset13_field_marbletable...   \n",
       "3    Robot_Arm_Data/bright_offset14_cafe2_marbletab...   \n",
       "5    Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "6    Robot_Arm_Data/dark_offset17_cafe1_marbletable...   \n",
       "..                                                 ...   \n",
       "385  Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "386  Robot_Arm_Data/dark_default_cam/image_20250325...   \n",
       "387  Robot_Arm_Data/bright_default_cam/image_202503...   \n",
       "389  Robot_Arm_Data/dark_offset15_cafe2_marbletable...   \n",
       "391  Robot_Arm_Data/dark_offset4_mud/image_20250326...   \n",
       "\n",
       "                                                prompt  \\\n",
       "1                           Where can I pour my juice?   \n",
       "2    A few strawberries would make this snack perfect.   \n",
       "3    This ramen needs a bowl so I can eat it properly.   \n",
       "5            A piece of fruit sounds like a good idea.   \n",
       "6                 Please restore your default posture.   \n",
       "..                                                 ...   \n",
       "385     I could use something cold and sweet to drink.   \n",
       "386          I could go for something naturally sweet.   \n",
       "387           I want something sweet and juicy to eat.   \n",
       "389  Something cold and fizzy would go well with my...   \n",
       "391  I should find something I can reuse to reduce ...   \n",
       "\n",
       "                                                output  \\\n",
       "1    <obj>plastic_cup</obj> <pose>0.71,-1.185,0.548...   \n",
       "2    <obj>strawberry</obj> <pose>0.655,-0.765,0.58<...   \n",
       "3    <obj>bowl</obj> <pose>0.385,-0.02,0.58</pose> ...   \n",
       "5    <obj>peach</obj> <pose>0.605,-1.24,0.63</pose>...   \n",
       "6    <obj>reset</obj> <pose>0.32,-0.65897,1.5002</p...   \n",
       "..                                                 ...   \n",
       "385  <obj>coke_can</obj> <pose>0.575,-0.375,0.72</p...   \n",
       "386  <obj>peach</obj> <pose>0.605,-1.22,0.63</pose>...   \n",
       "387  <obj>peach</obj> <pose>0.95,-0.71,0.63</pose> ...   \n",
       "389  <obj>coke_can</obj> <pose>0.825,-0.3,0.72</pos...   \n",
       "391  <obj>plastic_cup</obj> <pose>0.615,-1.195,0.54...   \n",
       "\n",
       "                                  name                  object pos_out  \\\n",
       "1         dark_offset6_cafe1_cafetable  <obj>plastic_cup</obj>    None   \n",
       "2      dark_offset13_field_marbletable   <obj>strawberry</obj>    None   \n",
       "3    bright_offset14_cafe2_marbletable         <obj>bowl</obj>    None   \n",
       "5                   bright_default_cam        <obj>peach</obj>    None   \n",
       "6      dark_offset17_cafe1_marbletable        <obj>reset</obj>    None   \n",
       "..                                 ...                     ...     ...   \n",
       "385                 bright_default_cam     <obj>coke_can</obj>    None   \n",
       "386                   dark_default_cam        <obj>peach</obj>    None   \n",
       "387                 bright_default_cam        <obj>peach</obj>    None   \n",
       "389    dark_offset15_cafe2_marbletable     <obj>coke_can</obj>    None   \n",
       "391                   dark_offset4_mud  <obj>plastic_cup</obj>    None   \n",
       "\n",
       "    ori_out obj_out                                            raw_out  \\\n",
       "1      None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "2      None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "3      None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "5      None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "6      None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "..      ...     ...                                                ...   \n",
       "385    None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "386    None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "387    None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "389    None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "391    None    None  <<SYS>>\\nYou are a Visual Language Model Train...   \n",
       "\n",
       "                    pos_truth                              ori_truth  \\\n",
       "1       [0.71, -1.185, 0.548]    [0.35478, 0.71881, 0.30505, 0.5141]   \n",
       "2       [0.655, -0.765, 0.58]  [0.37508, 0.92699, -0.00045, 0.00284]   \n",
       "3        [0.385, -0.02, 0.58]        [0.4468, 0.8508, 0.2185, 0.147]   \n",
       "5        [0.605, -1.24, 0.63]        [0.4468, 0.8508, 0.2185, 0.147]   \n",
       "6    [0.32, -0.65897, 1.5002]    [0.70711, 0.0006, 0.00068, 0.70711]   \n",
       "..                        ...                                    ...   \n",
       "385     [0.575, -0.375, 0.72]  [0.37508, 0.92699, -0.00045, 0.00284]   \n",
       "386      [0.605, -1.22, 0.63]        [0.4468, 0.8508, 0.2185, 0.147]   \n",
       "387       [0.95, -0.71, 0.63]        [0.4468, 0.8508, 0.2185, 0.147]   \n",
       "389       [0.825, -0.3, 0.72]  [0.37508, 0.92699, -0.00045, 0.00284]   \n",
       "391    [0.615, -1.195, 0.548]    [0.35478, 0.71881, 0.30505, 0.5141]   \n",
       "\n",
       "       obj_truth                                       format_check  \n",
       "1    plastic_cup  [obj count = 0, pose count = 0, orient count =...  \n",
       "2     strawberry  [pose count = 0, orient count = 0, position is...  \n",
       "3           bowl  [obj count = 0, pose count = 0, orient count =...  \n",
       "5          peach  [obj count = 0, pose count = 0, orient count =...  \n",
       "6          reset  [obj count = 0, pose count = 0, orient count =...  \n",
       "..           ...                                                ...  \n",
       "385     coke_can  [obj count = 0, pose count = 0, orient count =...  \n",
       "386        peach  [orient count = 0, position is not listformat,...  \n",
       "387        peach  [obj count = 0, pose count = 0, orient count =...  \n",
       "389     coke_can  [obj count = 0, pose count = 0, orient count =...  \n",
       "391  plastic_cup  [obj count = 0, pose count = 0, orient count =...  \n",
       "\n",
       "[313 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "bleu_score = bleu.compute(predictions=results['raw_out'][:1], references=results['output'][:1])\n",
    "rouge_score = rouge.compute(predictions=results['raw_out'][:1], references=results['output'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<<SYS>>\\nYou are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\\n<</SYS>>\\n\\n[INST]  \\nA drink with some fizz would really hit the spot. [/INST] <obj>coke_can</obj> <pose>0.62,-0.1,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['raw_out'][:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<obj>coke_can</obj> <pose>0.635,-0.1,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['output'][:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.260352493035444,\n",
       " 'precisions': [0.2871287128712871,\n",
       "  0.27,\n",
       "  0.25252525252525254,\n",
       "  0.23469387755102042],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 3.3666666666666667,\n",
       " 'translation_length': 101,\n",
       " 'reference_length': 30}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.3256260631771295,\n",
       " 'rouge2': 0.2595202210190299,\n",
       " 'rougeL': 0.32395223000004203,\n",
       " 'rougeLsum': 0.32412370325476236}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = [i for i in results.index if i not in index]\n",
    "good = results.loc[pd.Index(good)].reset_index(drop=True)\n",
    "\n",
    "bad = results.loc[index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A drink with some fizz would really hit the spot.\n",
      "Robot_Arm_Data/bright_default_cam/image_20250325_082143_1.png\n",
      "<<SYS>>\n",
      "You are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n",
      "<</SYS>>\n",
      "\n",
      "[INST]  \n",
      "A drink with some fizz would really hit the spot. [/INST] <obj>coke_can</obj> <pose>0.6,-0.11,0.72</pose> <orient>0.37508,0.92699,-0.00045,0.00284</orient>\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "print(good['prompt'][i])\n",
    "print(good['images'][i])\n",
    "print(good['raw_out'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where can I pour my juice?\n",
      "Robot_Arm_Data/dark_offset6_cafe1_cafetable/image_20250331_150318_2.png\n",
      "<<SYS>>\n",
      "You are a Visual Language Model Trained to output robot arm end-effectors parameters.Base on the user requests, locate the appropriate object in the image and you must return the position and orientation to reach it in xml format.\n",
      "<</SYS>>\n",
      "\n",
      "[INST]  \n",
      "Where can I pour my juice? [/INST] <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s>\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "print(bad['prompt'][i])\n",
    "print(bad['images'][i])\n",
    "print(bad['raw_out'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<obj>coke_can <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\\s> <\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.qwenvl.utils import inference\n",
    "\n",
    "inference(model=model, tokenizer=processor, system_message=system_message,\n",
    "          image_path='Robot_Arm_Data/bright_default_cam/image_20250325_082143_1.png', \n",
    "          prompt='A drink with some fizz would really hit the spot.',\n",
    "          size=(854, 480), temperature=0.5, min_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on dataset of 392 records with batch size of 2 per iteration:\n",
      "All Images will be resized to (854, 480)\n",
      "Progress: 100.00%        |==================================================|\n",
      "Extracting true value from the output...\n",
      "[INFO] 53 records are excluded from the evaluation due to inconsistent output format\n",
      "\n",
      "CasualLM Evaluation:\n",
      "---------------------------------------------------------------\n",
      "BLEU Score          |                  0.8385                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Rouge Score         |                  0.9016                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Object Poistion (X,Y,Z) Evaluation:\n",
      "---------------------------------------------------------------\n",
      "Euclidean           |                  0.1263                 |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Regression          | X           | Y           | Z           |\n",
      "---------------------------------------------------------------\n",
      "RÂ² Score            | 0.6664      | 0.8660      | 0.9982      |\n",
      "Mean Absolute Error | 0.0710      | 0.0892      | 0.0010      |\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Object Orientation (X,Y,Z,W) Evaluation:\n",
      "------------------------------------------------------------------\n",
      "Mean Quaternion Error  |                 0.7152                 |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------\n",
      "3-Axis Rotation        | Roll        | Pitch       | Yaw         |\n",
      "------------------------------------------------------------------\n",
      "Mean Errors            | 0.6564      | 0.1340      | 0.2717      |\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Object Class Evaluation:\n",
      "---------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            bowl       1.00      0.98      0.99        52\n",
      "        coke_can       1.00      1.00      1.00        61\n",
      "           peach       0.94      0.94      0.94        49\n",
      "     plastic_cup       0.98      1.00      0.99        55\n",
      "           reset       1.00      1.00      1.00        10\n",
      "samsung_j8_black       1.00      1.00      1.00        55\n",
      "      strawberry       0.95      0.95      0.95        57\n",
      "\n",
      "        accuracy                           0.98       339\n",
      "       macro avg       0.98      0.98      0.98       339\n",
      "    weighted avg       0.98      0.98      0.98       339\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results, index = eval_model(model=model, tokenizer=processor, system_message=system_message, eval_dataset=data, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.qwenvl.utils import extract_position_and_orientation\n",
    "\n",
    "position = [extract_position_and_orientation(data['output'][i])[0] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: ('min': 0.32, 'mean': 0.6616836734693877, 'max': 1.025, 'range': 0.7049999999999998)\n",
      "Y: ('min': -1.37, 'mean': -0.6902783163265307, 'max': 0.065, 'range': 1.435)\n",
      "Z: ('min': 0.548, 'mean': 0.676765306122449, 'max': 1.5002, 'range': 0.9521999999999999)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X: ('min': {min(pose[0])}, 'mean': {np.mean(pose[0])}, 'max': {max(pose[0])}, 'range': {max(pose[0]) - min(pose[0])})\")\n",
    "print(f\"Y: ('min': {min(pose[1])}, 'mean': {np.mean(pose[1])}, 'max': {max(pose[1])}, 'range': {max(pose[1]) - min(pose[1])})\")\n",
    "print(f\"Z: ('min': {min(pose[2])}, 'mean': {np.mean(pose[2])}, 'max': {max(pose[2])}, 'range': {max(pose[2]) - min(pose[2])})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
